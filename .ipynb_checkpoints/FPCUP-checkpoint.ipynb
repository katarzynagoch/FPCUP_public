{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "981864e7",
   "metadata": {},
   "source": [
    "## FPCUP: Development of downstream applications supporting Sectoral Information System under Copernicus Climate Change Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ddba741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data model is fitted to [Corine Land Cover 2018 (CLC2018) dataset](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_CORINE_V20_100m), referring to land cover / land use status of year 2018. CLC2018 is one of the datasets produced within the frame the [Corine Land Cover programme](https://land.copernicus.eu/pan-european/corine-land-cover)\n",
    "\n",
    "# The classification algorithm is using radar and optical observations: \n",
    "# - for radar data, C-band Synthetic Aperture Radar Ground Range Detected ([Sentinel-1 SAR GRD](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S1_GRD?hl=en)) observations for period May-August 2018 were used\n",
    "# - for optical data, MultiSpectral Instrument, Level-2A ([Sentinel-2](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR)) observations for May-October 2018 were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c6cb77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce71fd2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment the following line to install [geemap](https://geemap.org) if needed.\n",
    "# Add if statement for installing geemap on the client-side if not installed yet\n",
    "# !pip install geemap\n",
    "#geemap.update_package()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f8ee04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e82f4f9e6204549a656c4014d44a80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[0, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togglâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LIBRARIES\n",
    "import ee\n",
    "import geemap\n",
    "import geojson\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from ipyleaflet import WidgetControl\n",
    "\n",
    "username = 'yourGEEusername'\n",
    "Map = geemap.Map(center=[0,0])\n",
    "Map\n",
    "#ee.Initialize() do not use ee.Initialize: https://github.com/giswqs/geemap/discussions/705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "976409b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "def getObservationPeriod(source,year):\n",
    "    aperiod = {\n",
    "        'S1': [''.join([str(year),'-06-01']),''.join([str(year),'-06-30'])],\n",
    "        'S2': [''.join([str(year),'-06-01']),''.join([str(year),'-09-01'])],\n",
    "        'S12': []\n",
    "    }\n",
    "    \n",
    "    aperiod = ee.Dictionary(aperiod)\n",
    "\n",
    "    return aperiod.get(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "996f8865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create GEOJSON object that will define AOI (we select Karczew)\n",
    "def getGeoJSONdict():\n",
    "    geoJSONdict = {\n",
    "    'Poland': {\"type\": \"FeatureCollection\",\"features\": [{\"type\": \"Feature\",\"properties\": {},\"geometry\": {\n",
    "    \"type\": \"Polygon\",\"coordinates\": [[\n",
    "        [21.236314773559567,52.06578922343797],\n",
    "        [21.26704216003418,52.06578922343797],\n",
    "        [21.26704216003418,52.07860926614804],\n",
    "        [21.236314773559567,52.07860926614804],\n",
    "        [21.236314773559567,52.06578922343797]]]}}]},\n",
    "    'Italy': {\"type\": \"FeatureCollection\",\"features\": [{\"type\": \"Feature\",\"properties\": {},\"geometry\": {\n",
    "        \"type\": \"Polygon\",\"coordinates\": [[\n",
    "            [12.337989807128906,41.787569011260516],\n",
    "            [12.37112045288086,41.787569011260516],\n",
    "            [12.37112045288086,41.799727312622814],\n",
    "            [12.337989807128906,41.799727312622814],\n",
    "            [12.337989807128906,41.787569011260516]]]}}]},\n",
    "    'Greece': {\"type\": \"FeatureCollection\",\"features\": [{\"type\": \"Feature\",\"properties\": {},\"geometry\": {\n",
    "    \"type\": \"Polygon\",\"coordinates\": [[\n",
    "        [22.988462448120114,40.65362015979758],\n",
    "        [23.04330825805664,40.65362015979758],\n",
    "        [23.04330825805664,40.67679759855571],\n",
    "        [22.988462448120114,40.67679759855571],\n",
    "        [22.988462448120114,40.65362015979758]]]}}]},\n",
    "    'testArea': {\"type\": \"FeatureCollection\",\"features\": [{\"type\": \"Feature\",\"properties\": {},\"geometry\": {\n",
    "        \"type\": \"Polygon\",\"coordinates\": [[[12.377450466156006,41.79313651970495],[12.391312122344969,41.79313651970495],\n",
    "                                           [12.391312122344969,41.799807293811114],[12.377450466156006,41.799807293811114],\n",
    "                                           [12.377450466156006,41.79313651970495]]]}}]}}\n",
    "    return geoJSONdict\n",
    "\n",
    "def getAOI(country):\n",
    "    # Create GEE geometry AOI object\n",
    "    coords = getGeoJSONdict()[country]['features'][0]['geometry']['coordinates']\n",
    "    aoi = ee.Geometry.Polygon(coords)\n",
    "    \n",
    "    return aoi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8434b78f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load polygon from geoJSON\n",
    "def getGeoJSONPolygon(country):\n",
    "    # Open GeoJSON \n",
    "    f = 'IT_Sacrofano_municipality.geojson'\n",
    "    # Open the geojson dictionary\n",
    "    with open(f, encoding='UTF-8') as f:\n",
    "        gj = geojson.load(f)   \n",
    "    # From the GeoJSON collection, filter a selected NUTS region\n",
    "    gj['features'] = [nut for nut in gj['features'] if nut['properties']['FID'] == 5437]\n",
    "    # Create GEE geometry MultiPolygon object\n",
    "    coords = gj['features'][0]['geometry']['coordinates']\n",
    "    return ee.Geometry.MultiPolygon(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5821f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################# Corine Land Cover #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "929f10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://gis.stackexchange.com/questions/317305/remap-with-number-limits-and-not-individual-values-in-gee\n",
    "# Function to reclassify values defined by a range of values \n",
    "# @param {ee.Image}: image CLC image\n",
    "# @param {number}: lowerLimit values higher or equal to this limit will be masked with new value\n",
    "# @param {number}: upperLimit values lower or equal to this limit will be masked with new value\n",
    "# @param {number}: newValue a new value masking the values within the specified range\n",
    "# @return {ee.Image}: image a reclassified CLC image\n",
    "def reclassifyCLC(image, lowerLimit, upperLimit, newValue):\n",
    "    mask = image.gte(lowerLimit).And(image.lte(upperLimit))\n",
    "    masked_image = image.where(mask, newValue)\n",
    "    return masked_image\n",
    "\n",
    "# Get the unique values from a CLC image\n",
    "def getUniqueValues(image, band):\n",
    "    # band in ['landcover', 'classification']\n",
    "    imagedict = image.reduceRegion(reducer=ee.Reducer.toList())\n",
    "    return list(set(imagedict.getInfo()[band]))\n",
    "\n",
    "def getCLCreclassified(clc): \n",
    "    # # Aggregate CLC classes to get clear division into natural, urban, forest/grasslands and agricultural areas\n",
    "    clc2018recl = reclassifyCLC(clc, 100, 133, 0)    # urban areas (0)\n",
    "    clc2018recl = reclassifyCLC(clc2018recl, 141, 142, 1) # green urban areas (1)\n",
    "    clc2018recl = reclassifyCLC(clc2018recl, 211, 244, 2) # agricultural areas (2)\n",
    "    clc2018recl = reclassifyCLC(clc2018recl, 311, 335, 3) # forest and semi natural areas (3)\n",
    "    clc2018recl = reclassifyCLC(clc2018recl, 411, 423, 4) # wetlands (4)\n",
    "    clc2018recl = reclassifyCLC(clc2018recl, 511, 523, 5) # water bodies (5)\n",
    "    \n",
    "    clc_recl_values, clc_recl_names, clc_recl_colors = getCLC_class_table()\n",
    "    clc2018recl = clc2018recl.set('landcover_class_values',clc_recl_values) \\\n",
    "                             .set('landcover_class_names',clc_recl_names) \\\n",
    "                             .set('landcover_class_palette', clc_recl_colors)\n",
    "    return clc2018recl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39239671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getCLC_class_table():\n",
    "    # Define reclassified CLC class table\n",
    "    CLC_class_table = \"\"\"\n",
    "    Value\tColor\tDescription\n",
    "    0\tE6004D\tUrban fabric\n",
    "    1\tFFA6FF\tGreen urban areas\n",
    "    2\tFFFFA8\tAgricultural areas\n",
    "    3\t80FF00\tForest and semi natural areas\n",
    "    4\tA6A6FF\tWetlands\n",
    "    5\t00CCF2\tWater bodies\n",
    "    \"\"\"\n",
    "    legend_dict = geemap.legend_from_ee(CLC_class_table)\n",
    "    clc_recl_values = [ int(x[0]) for x in list(legend_dict.keys()) ]\n",
    "    clc_recl_names = [ x[2:] for x in list(legend_dict.keys()) ]\n",
    "    clc_recl_colors = [ legend_dict[x] for x in list(legend_dict.keys()) ]\n",
    "    \n",
    "    return clc_recl_values, clc_recl_names, clc_recl_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e726673",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################# S2 #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b68e5e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE S2 CLOUDLESS MOSAIC\n",
    "# Script to mask clouds and shadows from S2 images based on Earth Engine developer community tutorial provided by Justin Braaten (jdbcode)\n",
    "# Tutorial: https://developers.google.com/earth-engine/tutorials/community/sentinel-2-s2cloudless\n",
    "# Justin Braaten GitHub profile: https://github.com/jdbcode\n",
    "\n",
    "# Function to filter and join the SR and s2cloudless collections\n",
    "def getS2collection_clouds(aoi, period):\n",
    "    period = ee.List(period)\n",
    "    # Assign maximum image cloud cover percent allowed in image collection\n",
    "    CLOUD_FILTER = 60\n",
    "    # Import and filter S2 SR.\n",
    "    S2collection = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(period.get(0),period.get(1))\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER)))\n",
    "\n",
    "    # Import and filter s2cloudless.\n",
    "    s2collection_cloudless = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(period.get(0),period.get(1)))\n",
    "\n",
    "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
    "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
    "        'primary': S2collection,\n",
    "        'secondary': s2collection_cloudless,\n",
    "        'condition': ee.Filter.equals(**{\n",
    "            'leftField': 'system:index',\n",
    "            'rightField': 'system:index'\n",
    "        })\n",
    "    }))\n",
    "\n",
    "# Function to add the s2cloudless probability layer and derived cloud mask as bands to an S2 SR image input.\n",
    "def addCloudBands(img):\n",
    "    # Assign cloud probability (%): values greater than are considered cloud\n",
    "    CLD_PRB_THRESH = 40\n",
    "    # Get s2cloudless image, subset the probability band.\n",
    "    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
    "\n",
    "    # Condition s2cloudless by the probability threshold value.\n",
    "    is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
    "\n",
    "    # Add the cloud probability layer and cloud mask as image bands.\n",
    "    return img.addBands(ee.Image([cld_prb, is_cloud]))\n",
    "\n",
    "# Function to add dark pixels, cloud projection, and identified shadows as bands to an S2 image output of addCloudBands()\n",
    "def addShadowBands(img):\n",
    "    # Assign maximum distance (km) to search for cloud shadows from cloud edges\n",
    "    CLD_PRJ_DIST = 2\n",
    "    # Assign Near-infrared reflectance: values less than are considered potential cloud shadow\n",
    "    NIR_DRK_THRESH = 0.15\n",
    "    \n",
    "    # Identify water pixels from the SCL band.\n",
    "    not_water = img.select('SCL').neq(6)\n",
    "\n",
    "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
    "    SR_BAND_SCALE = 1e4\n",
    "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
    "\n",
    "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
    "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
    "\n",
    "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n",
    "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST*10)\n",
    "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
    "        .select('distance')\n",
    "        .mask()\n",
    "        .rename('cloud_transform'))\n",
    "\n",
    "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
    "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
    "\n",
    "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
    "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))\n",
    "\n",
    "# Function to assemble all of the cloud and cloud shadow components and produce the final mask.\n",
    "def addCloudShadowMask(img):\n",
    "    # Assign distance (m) to dilate the edge of cloud-identified objects\n",
    "    BUFFER = 100\n",
    "    \n",
    "    # Add cloud component bands.\n",
    "    img_cloud = addCloudBands(img)\n",
    "\n",
    "    # Add cloud shadow component bands.\n",
    "    img_cloud_shadow = addShadowBands(img_cloud)\n",
    "\n",
    "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
    "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n",
    "\n",
    "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
    "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
    "    is_cld_shdw = (is_cld_shdw.focal_min(2).focal_max(BUFFER*2/20)\n",
    "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20})\n",
    "        .rename('cloudmask'))\n",
    "\n",
    "    # Add the final cloud-shadow mask to the image.\n",
    "    return img_cloud_shadow.addBands(is_cld_shdw)\n",
    "\n",
    "# Function to apply the cloud mask to each image in the collection. Images are output of addCloudShadowMask() function\n",
    "def applyCloudShadowMask(img):\n",
    "    # Subset the cloudmask band and invert it so clouds/shadow are 0, else 1.\n",
    "    not_cld_shdw = img.select('cloudmask').Not()\n",
    "\n",
    "    # Subset reflectance bands and update their masks, return the result.\n",
    "    #return img.select('B.*').updateMask(not_cld_shdw)\n",
    "    return img.select(['B2','B3','B4','B8']).updateMask(not_cld_shdw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "274c4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to mask clouds using the Sentinel-2 QA band\n",
    "# # @param {ee.Image} image Sentinel-2 image\n",
    "# # @return {ee.Image} cloud masked Sentinel-2 image\n",
    "# def maskS2clouds(image):\n",
    "#     qa = image.select('QA60')\n",
    "\n",
    "#     # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "#     cloudBitMask = 1 << 10;\n",
    "#     cirrusBitMask = 1 << 11;\n",
    "\n",
    "#     # Both flags should be set to zero, indicating clear conditions.\n",
    "#     mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "    \n",
    "#     return image.updateMask(mask).divide(10000)\n",
    "\n",
    "# # Function to add Sentinel-2 MSI: MultiSpectral Instrument, Level-2A data for 2018 for 10m resolution bands,\n",
    "# # pre-filtered with .filter() to get less cloudy granules\n",
    "# # @param {list} period list containing start date and end date of analysis in format ['YYYY-MM-DD','YYYY-MM-DD']\n",
    "# # @return {ee.ImageCollection} cloud masked Sentinel-2 images\n",
    "# def getS2dataset10m(period, aoi):\n",
    "#     period = ee.List(period)\n",
    "#     S2_collection = ee.ImageCollection('COPERNICUS/S2_SR') \\\n",
    "#                 .filterDate(period.get(0),period.get(1)) \\\n",
    "#                 .filterBounds(aoi) \\\n",
    "#                 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20)) \\\n",
    "#                 .map(maskS2clouds) \\\n",
    "#                 .select(['B4','B3','B2','B8'])\n",
    "#     return S2_collection\n",
    "\n",
    "# # Function to add Sentinel-2 MSI: MultiSpectral Instrument, Level-2A data for 2018 for 20m resolution bands,\n",
    "# # pre-filtered with .filter() to get less cloudy granules\n",
    "# # @param {list} period list containing start date and end date of analysis in format ['YYYY-MM-DD','YYYY-MM-DD']\n",
    "# # @return {ee.ImageCollection} cloud masked Sentinel-2 images\n",
    "# def getS2dataset20m(period, aoi):\n",
    "#     period = ee.List(period)\n",
    "#     S2_collection = ee.ImageCollection('COPERNICUS/S2_SR') \\\n",
    "#                 .filterDate(period.get(0),period.get(1)) \\\n",
    "#                 .filterBounds(aoi) \\\n",
    "#                 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20)) \\\n",
    "#                 .map(maskS2clouds) \\\n",
    "#                 .select(['B5','B6','B7','B8A'])\n",
    "#     return S2_collection\n",
    "\n",
    "\n",
    "\n",
    "# # Function to check if there is at least one image in the image collection\n",
    "# # @param {ee.ImageCollection} any ee Image Collection\n",
    "# # @return {ee.Image} boolean mask image\n",
    "# def checkImageCollection(collection):   \n",
    "#     return collection.size().gt(ee.Number(0)).getInfo()==1\n",
    "\n",
    "# def getS2image(period, aoi, reproject=False, crs=None):\n",
    "#     # Get the image collection for a selected period\n",
    "#     if reproject is True:\n",
    "#         imgCollection = getS2dataset20m(period, aoi)\n",
    "#     else:\n",
    "#         imgCollection = getS2dataset10m(period, aoi)\n",
    "#     # Check if there are images in the collection\n",
    "#     #print('Image collection in ',period,' contains at least one valid picture: ',checkImageCollection(imgCollection))\n",
    "#     # Sort and select the one, least cloudy image\n",
    "#     image = getImageLeastClouds(imgCollection)\n",
    "#     # Reproject if needed\n",
    "#     if reproject is True:\n",
    "#         the_image = image.reproject(crs = crs, scale=10.0)\n",
    "#     else:\n",
    "#         the_image = image\n",
    "        \n",
    "#     return the_image\n",
    "\n",
    "# def getS2_bandNames():\n",
    "#     S2bands10m = ['S2_B4','S2_B3','S2_B2','S2_B8']\n",
    "#     S2bands20_to_10m = ['S2_B5','S2_B6','S2_B7','S2_B8A']\n",
    "    \n",
    "#     return S2bands10m, S2bands20_to_10m\n",
    "\n",
    "# Function to get a Sentinel-2 image composite in 10 m resolution for a specified period\n",
    "# @param {list} S2_trainingPeriods list containing start date and end date of analysis in format ['YYYY-MM-DD','YYYY-MM-DD']\n",
    "# @return {ee.Image} a composite S2 image reprojected to 10.0 m resolution\n",
    "# def createS2compositeImage(trainingPeriod, aoi):\n",
    "#     # Get the least cloudy image from bands with 10m resolution for S2 period of observation\n",
    "#     S2_image_10m = getS2image(trainingPeriod, aoi, reproject=False)\n",
    "\n",
    "#     # Get the least cloudy image from bands with 20m resolution for S2 period of observation and reproject to 10m\n",
    "#     S2_image_20_to_10m = getS2image(trainingPeriod, aoi, reproject=True, crs=getS2crs(aoi))\n",
    "\n",
    "#     # Get the names of the bands per native resolution\n",
    "#     S2bands10m, S2bands20_to_10m = getS2_bandNames()\n",
    "#     # Stack the images as bands in one image collection\n",
    "#     S2_image_reprojected = ee.ImageCollection([S2_image_10m,\n",
    "#                                   S2_image_20_to_10m]) \\\n",
    "#                     .toBands() \\\n",
    "#                     .rename(S2bands10m+S2bands20_to_10m) \\\n",
    "#                     .clip(aoi)\n",
    "#     return S2_image_reprojected\n",
    "\n",
    "def createS2mosaicImage(period, aoi):\n",
    "    S2collection_clouds= getS2collection_clouds(aoi, period)\n",
    "    # Add cloud and cloud shadow component bands to each image and then apply the mask to each image. \n",
    "    # Reduce the collection by median to a single image and clip to the area of interest\n",
    "    S2image_no_clouds = (S2collection_clouds.map(addCloudShadowMask)\n",
    "                         .map(applyCloudShadowMask)\n",
    "                         .median()\n",
    "                         .clip(aoi))\n",
    "    return S2image_no_clouds\n",
    "\n",
    "def getLeastCloudyS2Image(ayear, aoi):\n",
    "    # Get periods of analysis\n",
    "    aperiod = ee.List(getObservationPeriod('S2',ayear))\n",
    "    # Get S2 least cloudy image in the first year\n",
    "    return (ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "                     .filterDate(aperiod.get(0),aperiod.get(1))\n",
    "                     .filterBounds(aoi)\n",
    "                     .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20))\n",
    "                     .select(['B4','B3','B2'])\n",
    "                           .sort('CLOUD_COVER')\n",
    "                           .first()\n",
    "                           .clip(aoi))\n",
    "    \n",
    "def addS2_layers(startYear, endYear, aoi):\n",
    "    # Assign visualisation\n",
    "    S2_RGB = {'min': 0.0, 'max': 3000, 'bands': ['B4', 'B3', 'B2']}\n",
    "    \n",
    "    # Get S2 least cloudy image in the first year\n",
    "    S2_RGB_start = getLeastCloudyS2Image(startYear, aoi)\n",
    "    # Get S2 least cloudy image in the end year\n",
    "    S2_RGB_end = getLeastCloudyS2Image(endYear, aoi)\n",
    "\n",
    "    # Add S2 images to the map as layers\n",
    "    Map.addLayer(S2_RGB_start,S2_RGB,str(startYear),True)\n",
    "    Map.addLayer(S2_RGB_end,S2_RGB,str(endYear),True)\n",
    "    \n",
    "# # Get the common projection for further analysis from 10m band of Sentinel-2 image\n",
    "# def getS2crs(aoi):\n",
    "#     return getS2dataset10m(getObservationPeriod('S2',2018), aoi).select('B4').first().projection().crs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c95536fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add Sentinel-1 SAR GRD: C-band Synthetic Aperture Radar Ground Range Detected, log scale, 10 m resolution\n",
    "# @param {list} period list containing start date and end date of analysis in format ['YYYY-MM-DD','YYYY-MM-DD']# @param {string} endDate ending date of the image collection acquisition in format 'yyy-mm-dd'\n",
    "# @return {ee.ImageCollection} Sentinel-1 images\n",
    "def getS1dataset(period, aoi):\n",
    "    period=ee.List(period)\n",
    "    S1_collection = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "                .filterBounds(aoi) \\\n",
    "                .filterDate(period.get(0),period.get(1)) \\\n",
    "                .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    "                .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')) \\\n",
    "                .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
    "    return S1_collection\n",
    "\n",
    "# Function to get the median value of pixels\n",
    "# @param {ee.FeatureCollection} collection of Sentinel-1 images\n",
    "# @return {ee.Image} median value of pixels in the image collection\n",
    "def getMedian(featurecollection, aoi):\n",
    "    return featurecollection.median().clip(aoi)\n",
    "\n",
    "# Function to create a composite combining the three polarisation modes (VV, VH, and VV-VH)\n",
    "# @param {ee.Image} S1_image a Sentinel-1 images\n",
    "# @return {ee.Image} a composite S1 image with each polarisation mode stacked as a band\n",
    "\n",
    "# \"A three-band composite image, combining the three polarisation modes (VV, VH, and VV-VH), \n",
    "# has been reported optimal for land cover characterisation\" (Abdikan et al., 2014)\n",
    "def getS1compositeImage(S1_image):\n",
    "    return ee.ImageCollection([S1_image.select('VV'),\n",
    "                               S1_image.select('VH'),\n",
    "                               S1_image.select('VV').subtract(S1_image.select('VH'))]) \\\n",
    "                .toBands() \\\n",
    "                .rename(['VV','VH','VV-VH'])\n",
    "\n",
    "# # Function to reproject an image to S2 resolution\n",
    "# # @param {ee.Image} image an image\n",
    "# # @return {ee.Image} an image reprojected to S1 image CRS and 10.0 m resolution\n",
    "# def reproject_to_S2crs(image, aoi):\n",
    "#     return image.reproject(crs = getS2crs(aoi), scale=10.0)\n",
    "\n",
    "# Function to get a Sentinel-1 image composite in S2 resolution for specified period\n",
    "# @param {list} period_S1 start date and end date of analysis in format ['YYYY-MM-DD','YYYY-MM-DD']\n",
    "# @return {ee.Image} a composite S1 image reprojected to S2 image CRS and 10.0 m resolution\n",
    "def createS1compositeImage(period_S1, aoi):\n",
    "    # Sentinel-1 ground range detected images converted to decibels\n",
    "    S1GRD_dataset = getS1dataset(period_S1, aoi)\n",
    "    # Get the median value of pixels in the S1 collection\n",
    "    S1db_image = getMedian(S1GRD_dataset, aoi)\n",
    "    # Make composite image (VV,VH,VV-VH)\n",
    "    S1composite_image = getS1compositeImage(S1db_image)\n",
    "    # Get the common projection for further analysis from 10m band of Sentinel-2 image\n",
    "    S2_CRS = (ee.ImageCollection('COPERNICUS/S2_SR').select('B4').first().projection().crs())\n",
    "    # Reproject the composite to adjust to S2 CRS\n",
    "    return S1composite_image.reproject(crs = S2_CRS, scale=10.0)\n",
    "    #return reproject_to_S2crs(S1composite_image, aoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "053a5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a composite from S1 composite and S2 images\n",
    "def getS1S2composite(S1image, S2image):\n",
    "    # Get the names of the bands per native resolution\n",
    "    #S2bands10m, S2bands20_to_10m = getS2_bandNames()\n",
    "    \n",
    "    imagecollection = ee.ImageCollection([S1image,S2image]) \\\n",
    "                .toBands()\n",
    "                #.rename(['S1_VV','S1_VH','S1_VV-VH'] + S2bands10m + S2bands20_to_10m)\n",
    "\n",
    "    return imagecollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "459cf207",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################# Classifier #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b5e1ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getTrainingInputImage(source, aoi):\n",
    "#     # Create a dictionairy which stores different input ee.Image depending on the satellite source chosen\n",
    "#     trainDict = ee.Dictionary({\n",
    "#         'S1': createS1compositeImage(getObservationPeriod('S1',2018), aoi),\n",
    "#         'S2': createS2mosaicImage(getObservationPeriod('S2',2018), aoi),\n",
    "#         'S12': getS1S2composite(\n",
    "#             createS1compositeImage(getObservationPeriod('S1',2018), aoi),\n",
    "#             createS2mosaicImage(getObservationPeriod('S2',2018), aoi))    # composite exists!    \n",
    "#     })\n",
    "        \n",
    "#     return trainDict.get(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "620ccba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the ratio between a given area and the area of the whole AOI\n",
    "def getNumPoints(maxNumPoints, aoi):\n",
    "    aoi_km2 = aoi.area().divide(1e6)\n",
    "    def getRatio(class_area):\n",
    "        return ee.Number(class_area).divide(aoi_km2).multiply(maxNumPoints).round()\n",
    "    return getRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7456b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The scale and the projection is not specified, so the resolution of the image will be used\n",
    "# Change sampling to one sample set divided into two subsets for calibration and validation\n",
    "def getSamplePoints(clcRecl, aoi):\n",
    "    # Get the list of classes in CLC\n",
    "    clc_classes = ee.List(clcRecl.get('landcover_class_values'))\n",
    "    # Get the number of samples for CLC (100m x 100m = 10000) in the aoi\n",
    "    max_numSamples = ee.Number(aoi.area()).divide(10000).round()\n",
    "    # Count the area of each class in CLC map [km2]\n",
    "    class_areas = clc_classes.map(getClassAreaSqKm(clcRecl,aoi,'landcover')) # ee.List of areas in km2\n",
    "    # Get the number of points sampled from each class, depending on the ratio of the area of this class to the whole area\n",
    "    sample_points_per_class = class_areas.map(getNumPoints(max_numSamples, aoi))\n",
    "    \n",
    "    # Create a set of samples\n",
    "    sample_points = clcRecl.stratifiedSample(**{\n",
    "        'classBand': 'landcover',\n",
    "        'region': aoi,\n",
    "        'numPoints': 5000, # minimum number of points to sample in each class\n",
    "        'classValues': clc_classes, # reclassified land cover classes for CLC maps\n",
    "        'classPoints': sample_points_per_class, # maxium number of points to sample in each class \n",
    "        'seed': 0, # Set this to reproduce results\n",
    "        'geometries': True\n",
    "    })\n",
    "    \n",
    "    # add a column with uniformly distributed random values between 0 and 1\n",
    "    sample_points_random = sample_points.randomColumn('randomValue')\n",
    "    \n",
    "    return sample_points_random\n",
    "\n",
    "# Get 80% of samples for calibration\n",
    "def getSamplePoints_training(samples):\n",
    "    c_samples = samples.filter(ee.Filter.gt('randomValue',0.2))\n",
    "    #Map.addLayer(c_samples,{}, 'c_samples')\n",
    "    return c_samples\n",
    "\n",
    "# Get 20% of samples for validation\n",
    "def getSamplePoints_validation(samples):\n",
    "    v_samples = samples.filter(ee.Filter.lte('randomValue',0.2))\n",
    "    #Map.addLayer(v_samples,{}, 'v_samples')\n",
    "    return v_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bf04c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Overlay the points on the sattelite imagery to get training samples:\n",
    "def getSampledPoints(source_image, samples, aoi):\n",
    "    image = ee.Image(source_image)\n",
    "    sampled_points = image.sampleRegions(**{\n",
    "            'collection': samples,\n",
    "            'properties': ['landcover'],\n",
    "            'scale': 100\n",
    "        })\n",
    "    return sampled_points\n",
    "    \n",
    "def getClassifier(source_image, clc, aoi, clc_samples):\n",
    "    source = ee.Image(source_image)\n",
    "    # Get the overlay samples of the input sattelite data and CLC image\n",
    "    training_points = getSampledPoints(source_image, getSamplePoints_training(clc_samples),aoi)\n",
    "    # Train the classifier\n",
    "    classifier = ee.Classifier.smileRandomForest(500).train(training_points,'landcover')\n",
    "    # Train the model and return the classifier\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4e4f031",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getResubstitutionAccuracy(classifier):\n",
    "    return classifier.confusionMatrix()\n",
    "\n",
    "def getExpectedAccuracy(source_image, classifier, clcRecl, aoi, clc_samples):\n",
    "    # Get reference data for validation\n",
    "    validation_points = getSampledPoints(source_image, getSamplePoints_validation(clc_samples), aoi)\n",
    "    # Probably need to filter for empty features\n",
    "    \n",
    "    # Classify the validation samples\n",
    "    validated = validation_points.classify(classifier)\n",
    "    # Get the error matric\n",
    "    return validated.errorMatrix('landcover', 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d42641f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################# Detect Land Use Change (LUC) #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a840f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLUC_class_table():\n",
    "    # Evaluate Land Use Change\n",
    "    LUC_class_table = \"\"\"\n",
    "    Value\tColor\tDescription\n",
    "    10\tFBFBE4\tNo change\n",
    "    20\tf8f8ce\tRetained / reclassified\n",
    "    30\tb4ef86\tDeurbanisation\n",
    "    40\t05baae\tAfforestation\n",
    "    50\te47474\tUrbanisation\n",
    "    60\tac74e4\tNatural to agricultural areas\n",
    "    \"\"\"\n",
    "    LUC_dict = geemap.legend_from_ee(LUC_class_table)\n",
    "    LUC_values = [ int(x[:2]) for x in list(LUC_dict.keys()) ]\n",
    "    LUC_names = [ x[2:] for x in list(LUC_dict.keys()) ]\n",
    "    LUC_colors = [ LUC_dict[x] for x in list(LUC_dict.keys()) ]\n",
    "    \n",
    "    return LUC_dict, LUC_values, LUC_names, LUC_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab30ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for LUC detection\n",
    "\n",
    "# Function to get the observation days depending on the source (S1 radar and S2 optical)\n",
    "# @param {string}: imagesource selected Sentinel or a composite of images as the image source, in ['S1,'S2,'S12']\n",
    "# @param {number}: year year of the image production\n",
    "# @return {list}: period a list containing exact days of observation\n",
    "def getModelPeriod(imagesource, year):  \n",
    "    return getObservationPeriod(imagesource,year)  \n",
    "\n",
    "# Function to get the image cmoposite created using specified bands and resolution for a selected year and from selected sattelite\n",
    "# @param {string}: imagesource selected Sentinel or a composite of images as the image source, in ['S1,'S2,'S12']\n",
    "# @param {number}: year year of the image production\n",
    "# @return {ee.Image}: image image composite created using specified bands and resolution from selected sattelite source\n",
    "def getModelImage(imagesource, year,aoi):\n",
    "    period = getModelPeriod(imagesource, year)\n",
    "    if imagesource == 'S1':\n",
    "        image = createS1compositeImage(period,aoi)\n",
    "    else:\n",
    "        image = createS2mosaicImage(period,aoi)\n",
    "        \n",
    "    return image \n",
    "\n",
    "# Function to get the image composite of images from two Sentinel inputs: Sentinel-1 and Sentinel-2\n",
    "# @param {number}: year year of the image production\n",
    "# @return {ee.Image}: image image composite created using specified bands and resolution from Sentinel-1 and Sentinel-2 observations\n",
    "def getModelCompositeImage(year,aoi):\n",
    "    return getS1S2composite(getModelImage('S1',year,aoi),getModelImage('S2',year,aoi))\n",
    "\n",
    "# Function to get the Land Use Model for a selected year using observations from given sattelite input\n",
    "# @param {string}: imagesource selected Sentinel or a composite of images as the image source, in ['S1,'S2,'S12']\n",
    "# @param {number}: year year of the image production\n",
    "# @return {ee.Image}: classified image (a Land Use Model) trained on CLC 2018 data and reduced to CLC resolution\n",
    "def getLandUseModel(imagesource,year,classifier,aoi):\n",
    "    if imagesource in ['S1', 'S2']:\n",
    "        im = ee.Image(getModelImage(imagesource,year,aoi))\n",
    "    else:\n",
    "        im = ee.Image(getModelCompositeImage(year,aoi))\n",
    "# Snippet to model land use change in 100 m resolution. To be checked for CRS:    \n",
    "#     im_CLC = im\\\n",
    "#     .reduceResolution(reducer=ee.Reducer.mean(), maxPixels= 1024)\\\n",
    "#     .reproject(crs = clc2018.projection().crs(), scale=100.0)\\\n",
    "#     .classify(classifier)\n",
    "    im_CLC = im.classify(classifier)\n",
    "\n",
    "    return im_CLC\n",
    "\n",
    "# Function to get the Land Use Cover model for a selected year using observations from given sattelite input\n",
    "# @param {string}: imagesource selected Sentinel or a composite of images as the image source, in ['S1,'S2,'S12']\n",
    "# @param {number}: year year of the image production\n",
    "# @return {ee.Image}: classified image (a Land Use Cover model) where each class value has a specified name and color\n",
    "def getLandCoverModel(source,year,classifier,aoi):\n",
    "    clc_recl_values, clc_recl_names, clc_recl_colors = getCLC_class_table()\n",
    "    return getLandUseModel(source,year,classifier,aoi) \\\n",
    "                .set('classification_class_values', clc_recl_values) \\\n",
    "                .set('classification_class_palette', clc_recl_colors) \\\n",
    "                .set('classification_class_names',clc_recl_names) \n",
    "\n",
    "# Function to get a list of pairs of all possible combinations of LU classes \n",
    "def getIterations(a_list):\n",
    "    a_list = ee.List(a_list)\n",
    "    def mapList(element1):\n",
    "        def mapList_wrapper(element2):\n",
    "            return [element1, element2]\n",
    "        return mapList_wrapper\n",
    "\n",
    "    def iterateList(e1, acc):\n",
    "        pairs = a_list.map(mapList(e1))\n",
    "        return ee.List(acc).cat(pairs)\n",
    "\n",
    "    combinations = a_list.iterate(iterateList, ee.List([]))\n",
    "    return ee.List(combinations)\n",
    "\n",
    "# Function to create an Image with the evaluated LUC between two LU maps\n",
    "def maskTransitions(LU_start_map, LU_end_map):\n",
    "    empty_image = LU_start_map.multiply(0)\n",
    "    # wrapper to iterate over an ee.List()\n",
    "    def transitionWrapper(class_list):\n",
    "        # Assure that image is an ee.Image()...\n",
    "        image = ee.Image()\n",
    "        # Change the ee object to ee.List() object\n",
    "        class_list = ee.List(class_list)\n",
    "        # type of transition [x,y] is saved as the first subelement of each element of the main list\n",
    "        transition = class_list.get(0)\n",
    "        # change type of the transition to ee.List()\n",
    "        transition = ee.List(transition)\n",
    "        # Get the start LU type\n",
    "        c_s = ee.Number(transition.get(0))\n",
    "        # Get the end LU type\n",
    "        c_e = ee.Number(transition.get(1))\n",
    "        # The value (evaluation) of the transition is saved as the second subelement \n",
    "        evaluation = ee.Number(class_list.get(1))   \n",
    "        # Mask pixels for each transition from one class to another (a LUC class)\n",
    "        mask = LU_start_map.select('classification').eq(c_s).And(LU_end_map.select('classification').eq(c_e))\n",
    "        # Mask the empty map for the given transition\n",
    "        empty_map = LU_start_map.where(mask, evaluation)\n",
    "\n",
    "        return empty_map\n",
    "    \n",
    "    return transitionWrapper\n",
    "\n",
    "# Function to get the transition between land use class x to land use class y between two timesteps\n",
    "# @param {string}: source selected Sentinel or a composite of images as the classification input, in ['S1,'S2,'S12']\n",
    "# @return {ee.Image}: LUC_evaluated simplified LUC image\n",
    "# @return {dict}: LUC_legend_dict dictionairy containing names and colors for each class (value) on the image\n",
    "def getLandUseChange(LU_start, LU_end, source, classifier):\n",
    "    # Mask every possible combination of start - end classes and add to a Feature Collection\n",
    "    '''\n",
    "    LUC classes:\n",
    "    1-1: urban to urban\n",
    "    1-2: urban to green urban areas\n",
    "    ...\n",
    "    together 25 classes\n",
    "    '''\n",
    "    # Get the classes in start (or end) map, they are the same \n",
    "    LU_classes = ee.List(LU_start.get('classification_class_values'))\n",
    "    # Get every possible combinations of classes from the input list of classes\n",
    "    combinations = getIterations(LU_classes)\n",
    "    evaluated_combinations = ee.List(evaluateLUC())\n",
    "    # Evaluate the transitions (the Land Use Change)\n",
    "    classes = combinations.zip(evaluated_combinations)\n",
    "    # Iterate over the combination of classes and update the mask for each class transition. \n",
    "    # Each transition is saved in a band\n",
    "    LUC_evaluated = ee.ImageCollection(classes.map(maskTransitions(LU_start, LU_end))).toBands() \n",
    "    LUC_evaluated = LUC_evaluated.reduce(ee.Reducer.max()).rename(['classification'])        \n",
    "    \n",
    "    return LUC_evaluated                  \n",
    "\n",
    "# Function returning evaluation of the transition from one class to another. Function uses input from external Excel file.\n",
    "def evaluateLUC():\n",
    "    return [10,30,30,40,30,30,50,10,20,40,20,20,50,20,10,40,20,20,50,20,60,10,20,20,50,20,60,40,10,20,50,20,60,40,20,10]\n",
    "\n",
    "def getSources(year):\n",
    "    # Land Use Model can be taken from 3 different cources: S1, S2 or a composite of S1 and S2\n",
    "    # Temporal resolutions of each source: \n",
    "    validperiod = {\n",
    "        'S1': range(2015,2021+1),\n",
    "        'S2': range(2017,2021+1),\n",
    "        'S12': range(2017,2021+1)\n",
    "    }\n",
    "    # Land classification for both start and end date should be based on the same source\n",
    "    # Therefore, for years before 2018, only Sentinel 1 can be used\n",
    "    if year in validperiod['S2']:\n",
    "        return ee.List(['S1','S2','S12'])\n",
    "    elif year in validperiod['S1']:\n",
    "        return ee.List(['S1'])\n",
    "    else: print('Please select a year from range 2015-2021')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09588a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get a trained classifier and its classification error for each sattelite input\n",
    "def getClassifiers(roi, clc_samples, clc2018recl):\n",
    "    def sourceWrapper(s):\n",
    "        # Classify input satallite data using reclassified CLC as reference\n",
    "        classifier = getClassifier(s, clc2018recl, roi, clc_samples)\n",
    "        # Get a confusion matrix representing resubstitution accuracy\n",
    "        resubAcc = getResubstitutionAccuracy(classifier)\n",
    "        # Get a confusion matrix representing expected accuracy\n",
    "        expectAcc = getExpectedAccuracy(s,classifier, clc2018recl, roi, clc_samples)\n",
    "        # Update the dictionary with accuracy vaolues for each source\n",
    "        return classifier, resubAcc.accuracy(), expectAcc.accuracy()\n",
    "    return sourceWrapper\n",
    "\n",
    "def getSublistByIndex(i):\n",
    "    def sublistWrapper(alist):\n",
    "        return ee.List(alist).get(i)\n",
    "    return sublistWrapper\n",
    "\n",
    "# Function to calculate the area of each class in a map\n",
    "def getClassAreaSqKm(inputLUCmap, aoi, band):\n",
    "    # band in ['landcover', 'classification']\n",
    "    def classWrapper(aclass):\n",
    "        aclass = ee.Number(aclass)\n",
    "        # Band name in LUC map\n",
    "        LUCband = band\n",
    "        LUCclass = inputLUCmap.eq(aclass)\n",
    "        areaImage = LUCclass.multiply(ee.Image.pixelArea())\n",
    "        area = areaImage.reduceRegion(\n",
    "            reducer = ee.Reducer.sum(),\n",
    "            geometry = aoi,\n",
    "            scale=10,\n",
    "            maxPixels = 1e10)\n",
    "\n",
    "        return ee.Number(area.get(LUCband)).divide(1e6)\n",
    "    return classWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2008f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49514299a6704d2c9407b5fb38ce6727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Case study:', index=2, options=('Greece', 'Italy', 'Polandâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Designe interactive widgets\n",
    "style = {'description_width': 'initial'}\n",
    "output_widget = widgets.Output(layout={'border': '1px solid black'})\n",
    "output_control = WidgetControl(widget=output_widget, position='bottomright')\n",
    "Map.add_control(output_control)\n",
    "\n",
    "case_study_widget = widgets.Dropdown(\n",
    "    description='Case study:',\n",
    "    options=['Greece','Italy','Poland','testArea'],\n",
    "    value='Poland',\n",
    "    style=style)\n",
    "\n",
    "submit_widget = widgets.Button(\n",
    "    description='Submit',\n",
    "    button_style='primary',\n",
    "    tooltip='Click me',\n",
    "    style=style\n",
    ")\n",
    "start_year_widget = widgets.IntSlider(\n",
    "    description='Start Year:', \n",
    "    value=2017, \n",
    "    min=2017, \n",
    "    max=2021, \n",
    "    style=style)\n",
    "\n",
    "end_year_widget = widgets.IntSlider(\n",
    "    description='End Year:', \n",
    "    value=2021, \n",
    "    min=2017, \n",
    "    max=2021, \n",
    "    style=style)\n",
    "\n",
    "full_widget = widgets.VBox([widgets.HBox([case_study_widget, submit_widget, start_year_widget, end_year_widget])], \n",
    "                           width='200%')\n",
    "\n",
    "full_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6221d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################# MAIN #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8215670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export functions\n",
    "def printMessage(m, task, description):\n",
    "    while task.active():\n",
    "        print('.', end='')#print('Polling for task (id: {}).'.format(task.id))\n",
    "        time.sleep(5)\n",
    "    # After exporting, print info\n",
    "    print(m, description)\n",
    "    \n",
    "def exportToDrive(image, description, folder, aoi):\n",
    "    task = ee.batch.Export.image.toDrive(**{\n",
    "              'image': image,\n",
    "              'description': description,\n",
    "              'folder': folder,\n",
    "              'scale': 10,\n",
    "              'region': aoi\n",
    "            })\n",
    "    task.start()\n",
    "    # Wait, until the image is exported:\n",
    "    printMessage('exported to Drive', task, description)\n",
    "\n",
    "def createAsset(image, description, image_id, aoi):\n",
    "    # Delete old asset\n",
    "    ee.data.deleteAsset(image_id)\n",
    "    # And create a new one:\n",
    "    task = ee.batch.Export.image.toAsset(**{\n",
    "              'image': image,\n",
    "              'description': description,\n",
    "              'assetId': image_id,\n",
    "              'scale': 10,\n",
    "              'region': aoi\n",
    "            })\n",
    "    task.start()\n",
    "    # Adding as aimges as aseets takes a while. Wait, until the image is added:\n",
    "    printMessage('added as asset', task, description)\n",
    "    \n",
    "def assignLUCmetadata(LUC_image, LUC_values, LUC_names, LUC_colors):\n",
    "    # Set the names and the colors to each LUC class\n",
    "    return LUC_image.set('classification_class_values',LUC_values) \\\n",
    "                    .set('classification_class_names',LUC_names) \\\n",
    "                    .set('classification_class_palette',LUC_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c185de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle map interaction for user-drawn AOI\n",
    "def handle_interaction(**kwargs):\n",
    "    latlon = kwargs.get('coordinates')\n",
    "    if kwargs.get('type') == 'click':\n",
    "        Map.default_style = {'cursor': 'wait'}\n",
    "        xy = ee.Geometry.Point(latlon[::-1])\n",
    "        \n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "        \n",
    "            try:\n",
    "                print('yay')\n",
    "            except Exception as e:\n",
    "                print('No feature could be found')\n",
    "            \n",
    "        Map.default_style = {'cursor': 'pointer'}\n",
    "\n",
    "Map.on_interaction(handle_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "984b081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_clicked(b):\n",
    "    \n",
    "    with output_widget:\n",
    "        output_widget.clear_output()\n",
    "        if start_year_widget.value >= end_year_widget.value:\n",
    "            print('The end year must be greater than the start year.')\n",
    "            return\n",
    "        print('Computing...')\n",
    "        Map.default_style = {'cursor': 'wait'}\n",
    "\n",
    "        try:\n",
    "            # Remove produced layers from the map, if any, and leave only Google Map background\n",
    "            Map.layers = Map.layers[:2]\n",
    "            #Map.remove_legend()\n",
    "\n",
    "            ## Get the information for analysis\n",
    "            # Select the country\n",
    "            country = case_study_widget.value\n",
    "            #country='Italy'\n",
    "            # Select the period and available sattelite images\n",
    "            startYear = start_year_widget.value\n",
    "            endYear = end_year_widget.value\n",
    "            #sources = getSources(startYear)\n",
    "\n",
    "            ## Define AOI\n",
    "            # Get the json object for the AOI\n",
    "            aoi = getAOI(country)\n",
    "            #aoi = getGeoJSONPolygon(country)\n",
    "            aoi_area = aoi.area().divide(1e6).getInfo()\n",
    "            # Center map\n",
    "            Map.centerObject(aoi)\n",
    "            \n",
    "            ## Define Corine Land Cover data\n",
    "            # Load CLC for year 2018, which will be used as a reference data for training\n",
    "            clc2018 = ee.Image(\"COPERNICUS/CORINE/V20/100m/2018\").clip(aoi)\n",
    "            # Remap CLC values to simpler classification \n",
    "            clc2018recl = getCLCreclassified(clc2018)\n",
    "            # Samples points from CLC for training and validation\n",
    "            clc_samples = getSamplePoints(clc2018recl, aoi)          \n",
    "\n",
    "            ## Get data for training\n",
    "            # S1 data\n",
    "            S1_training = createS1compositeImage(getObservationPeriod('S1',2018), aoi)\n",
    "            # S2 data\n",
    "            S2_training = createS2mosaicImage(getObservationPeriod('S2',2018), aoi)\n",
    "            # S1 and S2 composite\n",
    "            S12_training = getS1S2composite(S1_training, S2_training)\n",
    "            # Create a list with training inputs\n",
    "            sources = ee.List(['S1','S2','S12'])\n",
    "            sources_training = ee.List([S1_training, S2_training, S12_training])\n",
    "\n",
    "            ## Train classifiers using different input data for training and select the one with lowest error         \n",
    "            # For every sattelite input get the classifier and the validation accuracy\n",
    "            classifiers_estimation = sources_training.map(getClassifiers(aoi, clc_samples, clc2018recl))\n",
    "            # Create a list of classifiers\n",
    "            classifiers = classifiers_estimation.map(getSublistByIndex(0))\n",
    "            # Create a list of resubstitution accuracy\n",
    "            resubAcc = classifiers_estimation.map(getSublistByIndex(1))\n",
    "            # Create a list of expected accuracy\n",
    "            expectedAcc = classifiers_estimation.map(getSublistByIndex(2))\n",
    "\n",
    "            # Find maximum accuracy value\n",
    "            maxAccuracy = expectedAcc.reduce(ee.Reducer.max())\n",
    "            # Find the position of the lowest error in list. \n",
    "            # indexof() returns the position of the first occurrence of target in list, so\n",
    "            # S1 will be chosen over S2, both S1 and S2 will be chosen over S12\n",
    "            index = expectedAcc.indexOf(maxAccuracy) \n",
    "            # Select the name of the input sattelite image\n",
    "            source = sources.get(index).getInfo()\n",
    "            # Select the classifier\n",
    "            classifier = classifiers.get(index)\n",
    "\n",
    "            ## Compute the Land Use Change data\n",
    "            # Get the Land Use map for the first year\n",
    "            LU_start = getLandCoverModel(source,startYear,classifier,aoi)\n",
    "            # Get the Land Use map for the last year\n",
    "            LU_end = getLandCoverModel(source,endYear,classifier,aoi)  \n",
    "            # Evaluate the difference between LU in start and end year and compute LUC map\n",
    "            LUC = getLandUseChange(LU_start, LU_end, source, classifier)\n",
    "            # Save LUC raster as an asset\n",
    "            createAsset(LUC, 'LUC', 'users/'+username+'/LUC', aoi)\n",
    "            LUC_asset = ee.Image(\"users/\"+username+\"/LUC\").clip(aoi)\n",
    "            # Get LUC metadata\n",
    "            LUC_dict, LUC_values, LUC_names, LUC_colors = getLUC_class_table()\n",
    "            # Assign LUC metadata\n",
    "            LUC = assignLUCmetadata(LUC, LUC_values, LUC_names, LUC_colors)\n",
    "            LUC_asset = assignLUCmetadata(LUC_asset, LUC_values, LUC_names, LUC_colors)\n",
    "                        \n",
    "            ## Dislpay results\n",
    "            # Add S2 RGB example images (remember that a mosaic is used for analysis!) for start and end year\n",
    "            addS2_layers(startYear, endYear,aoi)\n",
    "            # Add results to the map\n",
    "            #Map.addLayer(LU_start,{},' '.join(['model LU cover',str(startYear)]), shown=False)\n",
    "            #Map.addLayer(LU_end,{},' '.join(['model LU cover',str(endYear)]), shown=False)\n",
    "            Map.addLayer(LUC_asset,{},(' ').join(['LUC between',str(startYear),'and',str(endYear),'input:',source]))\n",
    "            #Map.add_legend(legend_title=\"Land Use Change\", legend_dict=LUC_dict)\n",
    "\n",
    "            ## Print input details\n",
    "            output_widget.clear_output()\n",
    "            # Print map info\n",
    "            print('aoi: ',country)\n",
    "            print('area:','{:.2f}'.format(aoi_area),'km2')\n",
    "            print(' '.join(['LUC period:',str(startYear),'-',str(endYear)]))\n",
    "            try:\n",
    "                print('sattelite sources available: ',sources.getInfo())\n",
    "            except:\n",
    "                print('Please select different start year')\n",
    "\n",
    "            print('Selected satelitte input:',source)\n",
    "            print('Validation overall accuracy:','{:.2f}'.format(expectedAcc.get(index).getInfo()))\n",
    "\n",
    "            ## Print output details\n",
    "            # Get the list of transition classes\n",
    "            classes = ee.List(LUC.get('classification_class_values'))\n",
    "            # Calculate the area of each transition class (km2)\n",
    "            class_areas = classes.map(getClassAreaSqKm(LUC,aoi,'classification'))\n",
    "            # Calculate the area of LUC map, omitting NoData areas\n",
    "            summed_class_areas = class_areas.reduce(ee.Reducer.sum()).getInfo()\n",
    "            print('LUC area:','{:.2f}'.format(summed_class_areas),'km2')\n",
    "            # Print the percentacge of area of each transition class\n",
    "            class_areas = class_areas.getInfo()\n",
    "            for i,c in enumerate(class_areas):\n",
    "                print(list(LUC_names)[i],':','{:.2f}'.format(c),'km2','{:.2f}'.format(c/summed_class_areas*100),'%')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e,'huh')\n",
    "            print('An error occurred during computation.')        \n",
    "\n",
    "        Map.default_style = {'cursor': 'default'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a67dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go for it\n",
    "submit_widget.on_click(submit_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87fba460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised classification script based on: https://developers.google.com/earth-engine/guides/classification  \n",
    "# Application functionality based on: https://geemap.org/notebooks/41_water_app/  \n",
    "# Application layout uses widget templates and gridstack template:  \n",
    "# https://blog.jupyter.org/introducing-templates-for-jupyter-widget-layouts-f72bcb35a662  \n",
    "# https://blog.jupyter.org/voila-gridstack-template-8a431c2b353e  \n",
    "\n",
    "# **References:**\n",
    "# 1) Abdikan, S., Sanli, F. B., Ustuner, M., & CalÃ², F. (2014, February). Land cover mapping using sentinel-1 SAR data. In The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume XLI-B7, 2016 XXIII ISPRS Congress.  \n",
    "\n",
    "# 2) Saini, R., & Ghosh, S. K. (2018). CROP CLASSIFICATION ON SINGLE DATE SENTINEL-2 IMAGERY USING RANDOM FOREST AND SUPPOR VECTOR MACHINE. International Archives of the Photogrammetry, Remote Sensing & Spatial Information Sciences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
